{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE765_Gait_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKo-6H6HfCoG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws3lVNe-nmWv"
      },
      "source": [
        "!pip install ipympl\n",
        "!pip install tf2crf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n87KgRnufHOW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime, os\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import tensorflow as tf\n",
        "from tf2crf import CRF\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, LSTM, Dense, Conv2D, Conv1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tf2crf import CRF, ModelWithCRFLoss, ModelWithCRFLossDSCLoss \n",
        "from sklearn.metrics import classification_report\n",
        "from numpy import transpose\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzAePI1pfLDO"
      },
      "source": [
        "path = '/content/gdrive/My Drive/ECE 765/Project/TrainingData/'\n",
        "import os\n",
        "files = sorted(os.listdir(path))\n",
        "i=0\n",
        "x = pd.DataFrame()\n",
        "x_time = pd.DataFrame()\n",
        "y = pd.DataFrame()\n",
        "y_time = pd.DataFrame()\n",
        "\n",
        "print(sorted(files))\n",
        "# files = files[0:9]\n",
        "for f in files:\n",
        "  temp = pd.read_csv(path+f,header=None)\n",
        "  if 'x_time' in f:\n",
        "    x_time = x_time.append(temp)\n",
        "  elif 'y_time' in f:\n",
        "    y_time = y_time.append(temp)\n",
        "  elif 'x' in f:\n",
        "    x = x.append(temp)\n",
        "  else:\n",
        "    result = pd.DataFrame(pd.np.repeat(temp.values,4,axis = 0))\n",
        "    y = y.append(result,ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2Q0XtPIfRcb"
      },
      "source": [
        "print(x_time.shape)\n",
        "print(x.shape)\n",
        "y = y[0:len(x)]\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_AJKNvfdJ-"
      },
      "source": [
        "x = x.rename(columns={0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\", 4: \"E\", 5: \"F\"})\n",
        "x['time'] = x_time\n",
        "x['label'] = y\n",
        "x_r=x.shape[0]\n",
        "x_c=x.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MbazOo8g5EX"
      },
      "source": [
        "''' Code block for sliding window '''\n",
        "w_size=160\n",
        "visible_data=np.array([])\n",
        "\n",
        "for i in range(0, x_r, int(w_size/2)):\n",
        "  if (i+w_size)<x_r:\n",
        "    window_data=x.iloc[i:i+w_size,0:6].values.flatten()  \n",
        "    window_label=x['label'][i:i+w_size].value_counts().idxmax()\n",
        "    \n",
        "    window_data=np.append(window_data, window_label)\n",
        "    if visible_data.size==0:\n",
        "      visible_data=np.hstack((visible_data, window_data))\n",
        "    else:\n",
        "      visible_data=np.vstack((visible_data, window_data))\n",
        "print(visible_data.shape)\n",
        "\n",
        "# # save to npy file\n",
        "# path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "# save(path+'data_window.npy', visible_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BtLBfff2qd"
      },
      "source": [
        "''' Code block for sliding window with 50% overlap for 160x6'''\n",
        "w_size=160\n",
        "visible_data=[]\n",
        "#print(visible_data.shape)\n",
        "\n",
        "for i in range(0, x_r, int(w_size/2)): #Slide throuhg all the rows with a 50% increment equivalent to 50% overlap \n",
        "  if (i+w_size)<x_r:\n",
        "    window_data=x.iloc[i:i+w_size,0:6].values\n",
        "    window_label=x['label'][i:i+w_size].value_counts().idxmax() #Chooses the mode value amongst the labels\n",
        "    label=np.full((w_size,1), window_label)\n",
        "    window_data=np.append(window_data,label,axis=1)\n",
        "    visible_data.append(window_data)\n",
        "\n",
        "visible_data=np.stack(visible_data, axis=0)\n",
        "print(visible_data.shape)\n",
        "\n",
        "# # save to npy file\n",
        "path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "save(path+'data_window160.npy', visible_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "I1ToYCSZlGwj"
      },
      "source": [
        "#@title\n",
        "''' FOR NEW DATA '''\n",
        "path = '/content/gdrive/My Drive/ECE 765/Project/TestData/'\n",
        "import os\n",
        "files = sorted(os.listdir(path))\n",
        "i=0\n",
        "x = pd.DataFrame()\n",
        "x_time = pd.DataFrame()\n",
        "y = pd.DataFrame()\n",
        "y_time = pd.DataFrame()\n",
        "print(len(files))\n",
        "print(sorted(files))\n",
        "# files = files[0:9]\n",
        "files = files[0:3]\n",
        "\n",
        "for f in files:\n",
        "  temp = pd.read_csv(path+f,header=None)\n",
        "  if 'x_time' in f:\n",
        "    x_time = x_time.append(temp,ignore_index=True)\n",
        "  elif 'y_time' in f:\n",
        "    y_time = y_time.append(temp,ignore_index=True)\n",
        "  elif 'x' in f:\n",
        "    x = x.append(temp,ignore_index=True)\n",
        "  else:\n",
        "    result = pd.DataFrame(pd.np.repeat(temp.values,4,axis = 0))\n",
        "\n",
        "    y = y.append(result,ignore_index=True)\n",
        "# # save to npy file\n",
        "# path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "# save(path+'subject_009.npy', visible_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EXIIUzOAlHMz"
      },
      "source": [
        "#@title\n",
        "''' FOR NEW DATA '''\n",
        "\n",
        "path = '/content/gdrive/My Drive/ECE 765/Project/TestData/'\n",
        "import os\n",
        "files = sorted(os.listdir(path))\n",
        "i=0\n",
        "x = pd.DataFrame()\n",
        "x_time = pd.DataFrame()\n",
        "y = pd.DataFrame()\n",
        "y_time = pd.DataFrame()\n",
        "print(len(files))\n",
        "print(sorted(files))\n",
        "# files = files[0:9]\n",
        "files = files[3:6]\n",
        "\n",
        "for f in files:\n",
        "  temp = pd.read_csv(path+f,header=None)\n",
        "  if 'x_time' in f:\n",
        "    x_time = x_time.append(temp,ignore_index=True)\n",
        "  elif 'y_time' in f:\n",
        "    y_time = y_time.append(temp,ignore_index=True)\n",
        "  elif 'x' in f:\n",
        "    x = x.append(temp,ignore_index=True)\n",
        "  else:\n",
        "    result = pd.DataFrame(pd.np.repeat(temp.values,4,axis = 0))\n",
        "\n",
        "    y = y.append(result,ignore_index=True)\n",
        "# # save to npy file\n",
        "# path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "# save(path+'subject_010.npy', visible_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gSEJTYz-lHiS"
      },
      "source": [
        "#@title\n",
        "''' FOR NEW DATA '''\n",
        "\n",
        "path = '/content/gdrive/My Drive/ECE 765/Project/TestData/'\n",
        "import os\n",
        "files = sorted(os.listdir(path))\n",
        "i=0\n",
        "x = pd.DataFrame()\n",
        "x_time = pd.DataFrame()\n",
        "y = pd.DataFrame()\n",
        "y_time = pd.DataFrame()\n",
        "print(len(files))\n",
        "print(sorted(files))\n",
        "# files = files[0:9]\n",
        "files = files[6:9]\n",
        "\n",
        "for f in files:\n",
        "  temp = pd.read_csv(path+f,header=None)\n",
        "  if 'x_time' in f:\n",
        "    x_time = x_time.append(temp,ignore_index=True)\n",
        "  elif 'y_time' in f:\n",
        "    y_time = y_time.append(temp,ignore_index=True)\n",
        "  elif 'x' in f:\n",
        "    x = x.append(temp,ignore_index=True)\n",
        "  else:\n",
        "    result = pd.DataFrame(pd.np.repeat(temp.values,4,axis = 0))\n",
        "\n",
        "    y = y.append(result,ignore_index=True)\n",
        "# # save to npy file\n",
        "# path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "# save(path+'subject_011.npy', visible_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qZuSrQPUf3L7"
      },
      "source": [
        "#@title\n",
        "''' FOR NEW DATA '''\n",
        "\n",
        "path = '/content/gdrive/My Drive/ECE 765/Project/TestData/'\n",
        "import os\n",
        "files = sorted(os.listdir(path))\n",
        "i=0\n",
        "x = pd.DataFrame()\n",
        "x_time = pd.DataFrame()\n",
        "y = pd.DataFrame()\n",
        "y_time = pd.DataFrame()\n",
        "print(len(files))\n",
        "print(sorted(files))\n",
        "# files = files[0:9]\n",
        "files = files[9:12]\n",
        "\n",
        "for f in files:\n",
        "  temp = pd.read_csv(path+f,header=None)\n",
        "  if 'x_time' in f:\n",
        "    x_time = x_time.append(temp,ignore_index=True)\n",
        "  elif 'y_time' in f:\n",
        "    y_time = y_time.append(temp,ignore_index=True)\n",
        "  elif 'x' in f:\n",
        "    x = x.append(temp,ignore_index=True)\n",
        "  else:\n",
        "    result = pd.DataFrame(pd.np.repeat(temp.values,4,axis = 0))\n",
        "\n",
        "    y = y.append(result,ignore_index=True)\n",
        "# # save to npy file\n",
        "# path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "# save(path+'subject_012.npy', visible_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwke0PjflU6q"
      },
      "source": [
        "path = '/content/gdrive/My Drive/ECE 765/Project/'\n",
        "data = np.load(path+'data_window.npy')\n",
        "test_009 = np.load(path+'subject_009.npy')\n",
        "test_010 = np.load(path+'subject_010.npy')\n",
        "test_011 = np.load(path+'subject_011.npy')\n",
        "test_012 = np.load(path+'subject_012.npy')\n",
        "test_009_length = 9498\n",
        "test_010_length = 12270\n",
        "test_011_length = 12940\n",
        "test_012_length = 11330\n",
        "\n",
        "print(data.shape)\n",
        "print(test_009.shape)\n",
        "print(test_010.shape)\n",
        "print(test_011.shape)\n",
        "print(test_012.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdmtiEQglrB8"
      },
      "source": [
        "''' Downsampling Code '''\n",
        "\n",
        "df = pd.DataFrame(data = data)\n",
        "# Counter({0: 12522, 3: 2590, 2: 933, 1: 726})\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority1 = df[df[960]==0]\n",
        "df_majority2 = df[df[960]==2]\n",
        "df_majority3 = df[df[960]==3]\n",
        "df_minority = df[df[960]==1]\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled1 = resample(df_majority1, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=2590,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "df_majority_downsampled2 = resample(df_majority2, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=933,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "df_majority_downsampled3 = resample(df_majority3, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=2590,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled1,df_majority_downsampled2,df_majority_downsampled3, df_minority])\n",
        " \n",
        "data = df_downsampled.to_numpy()\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnOQJbWDlxvs"
      },
      "source": [
        "X = data[:,0:960]\n",
        "y = data[:,960]\n",
        "y = y.astype('int32')\n",
        "print(set(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6OLYr2Ml0dc"
      },
      "source": [
        "scl = StandardScaler()\n",
        "scl = scl.fit(X)\n",
        "X = scl.transform(X)\n",
        "test_009 = scl.transform(test_009)\n",
        "test_010 = scl.transform(test_010)\n",
        "test_011 = scl.transform(test_011)\n",
        "test_012 = scl.transform(test_012)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDdCAkWkl1q-"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8-1pUGl32Q"
      },
      "source": [
        "''' Without Down sampling '''\n",
        "\n",
        "# class_weight = {0: 1.,\n",
        "#                 1: 17.24,\n",
        "#                 2: 13.42,\n",
        "#                 3:4.83}\n",
        "\n",
        "# With Down sampling\n",
        "\n",
        "\n",
        "class_weight = {0: 1.,\n",
        "                1: 3.56,\n",
        "                2: 2.77,\n",
        "                3:1.}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6FvzQ7omjga"
      },
      "source": [
        "original_dim = 960\n",
        "intermediate_dim1 = 512\n",
        "intermediate_dim2 = 256\n",
        "latent_dim = 64\n",
        "\n",
        "inputs = keras.Input(shape=(960,))\n",
        "h = layers.Dense(intermediate_dim1, activation='relu')(inputs)\n",
        "h1 = layers.Dense(intermediate_dim2, activation='relu')(h)\n",
        "z_mean = layers.Dense(latent_dim)(h1)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h1)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                              mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkNF3Obgmp_Y"
      },
      "source": [
        "# Create encoder\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x2 = layers.Dense(intermediate_dim2, activation='relu')(latent_inputs)\n",
        "x3 = layers.Dense(intermediate_dim1, activation='relu')(x2)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x3)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXwz8_rImqzk"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "...   if epoch < 10:\n",
        "...     return lr\n",
        "...   else:\n",
        "...     return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh086uFrmrfm"
      },
      "source": [
        "reconstruction_loss = keras.losses.mean_squared_logarithmic_error(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "vae.compile(optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26WtufzZm8xM"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nPMg-6HnATn"
      },
      "source": [
        "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnnHQMFCnBU9"
      },
      "source": [
        "hist = vae.fit(x_train, x_train, epochs=10, batch_size=128,validation_data=(x_test, x_test),callbacks=[tensorboard_callback,callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7xtPtzGnETx"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKckhCm2nJiC"
      },
      "source": [
        "x_train_encoded = encoder.predict(x_train)\n",
        "x_train_encoded = np.array(x_train_encoded)\n",
        "x_train_encoded = x_train_encoded[0,:]\n",
        "x_test_encoded = encoder.predict(x_test)\n",
        "x_test_encoded = np.array(x_test_encoded)\n",
        "x_test_encoded = x_test_encoded[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZJQySonSGr"
      },
      "source": [
        "num_classes = 4\n",
        "def make_model(input_shape):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    intermediate_dim = 128\n",
        "    gap = layers.Dense(intermediate_dim, kernel_initializer='uniform',activation='relu')(input_layer)\n",
        "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
        "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=x_train_encoded.shape[1:])\n",
        "# print(model.summary())\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzi6KVannXwu"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5, min_lr=0.01\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1),\n",
        "]\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate=1e-3,\n",
        "#     decay_steps=10000,\n",
        "#     decay_rate=0.9)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train_encoded,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(x_test_encoded,y_test),\n",
        "    verbose=1,\n",
        "    class_weight = class_weight\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBN24hyKne1m"
      },
      "source": [
        "y_pred = model.predict(x_test_encoded, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjWeevexqGwL"
      },
      "source": [
        "def make_model(input_shape):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    intermediate_dim1 = 512\n",
        "    intermediate_dim2 = 256\n",
        "    intermediate_dim3 = 64\n",
        "    intermediate_dim4 = 32\n",
        "    h = layers.Dense(intermediate_dim1, kernel_initializer='uniform',activation='relu')(input_layer)\n",
        "    h1 = layers.Dense(intermediate_dim2,kernel_initializer='uniform', activation='relu')(h)\n",
        "    h2 = layers.Dense(intermediate_dim3, kernel_initializer='uniform',activation='relu')(h1)\n",
        "    gap = layers.Dense(intermediate_dim4, kernel_initializer='uniform',activation='relu')(h2)\n",
        "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
        "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=x_train.shape[1:])\n",
        "# print(model.summary())\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvpKVMJEqL3h"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1),\n",
        "]\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate=1e-3,\n",
        "#     decay_steps=10000,\n",
        "#     decay_rate=0.9)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(x_test,y_test),\n",
        "    verbose=1,\n",
        "    class_weight = class_weight\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VrLSZpDqSdz"
      },
      "source": [
        "\n",
        "y_pred = model.predict(x_test, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQbAYtEo1aXU"
      },
      "source": [
        "x_train_encoded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJCngHPotq5B"
      },
      "source": [
        "x_train_encoded_list = list(x_train_encoded)\n",
        "y_train_list = list(y_train)\n",
        "y_train_list = transpose([y_train_list]*64)\n",
        "x_train_encoded_list = np.array(x_train_encoded_list)\n",
        "y_train_list = np.array(y_train_list)\n",
        "x_train_encoded_list = x_train_encoded_list.reshape((x_train_encoded_list.shape[0],x_train_encoded_list.shape[1],1))\n",
        "\n",
        "x_test_encoded_list = list(x_test_encoded)\n",
        "y_test_list = list(y_test)\n",
        "y_test_list = transpose([y_test_list]*64)\n",
        "x_test_encoded_list = np.array(x_test_encoded_list)\n",
        "y_test_list = np.array(y_test_list)\n",
        "x_test_encoded_list = x_test_encoded_list.reshape((x_test_encoded_list.shape[0],x_test_encoded_list.shape[1],1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvWlpJnCqm9h"
      },
      "source": [
        "inputs = Input(shape=(x_train_encoded_list.shape[1:]))\n",
        "# output = Embedding(10, 1, trainable=True, mask_zero=True)(inputs)\n",
        "# output = Embedding(10, 1, trainable=True, mask_zero=True)(inputs)\n",
        "\n",
        "output =     Conv1D(64, 3, activation='relu',padding='same')(inputs)\n",
        "\n",
        "\n",
        "# output = Bidirectional(LSTM(64, return_sequences=True))(output)\n",
        "output = Bidirectional(LSTM(64, return_sequences=True))(output)\n",
        "\n",
        "output = Dense(4, activation='softmax')(output)\n",
        "crf = CRF(dtype='float32')\n",
        "output = crf(output)\n",
        "base_model = Model(inputs, output)\n",
        "model = ModelWithCRFLoss(base_model)\n",
        "model.compile(optimizer='adam')\n",
        "# print(base_model.summary())\n",
        "\n",
        "\n",
        "model.fit(x=x_train_encoded_list, y=y_train_list, epochs=2,validation_data=(x_test_encoded_list,y_test_list),class_weight = class_weight)\n",
        "# keras.utils.plot_model(base_model)\n",
        "keras.utils.plot_model(base_model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK78xM3GzWvb"
      },
      "source": [
        "model.evaluate(x_test_encoded_list,y_test_list)\n",
        "y_pred = model.predict(x_test_encoded, batch_size=64, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YQFYtz6ngX-"
      },
      "source": [
        "#@title\n",
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXem6VUdpZDN"
      },
      "source": [
        "#@title\n",
        "subject_009_predict =  model.predict(test_009)\n",
        "subject_010_predict =  model.predict(test_010)\n",
        "subject_011_predict =  model.predict(test_011)\n",
        "subject_012_predict =  model.predict(test_012)\n",
        "labels_009 = np.argmax(subject_009_predict, axis=-1)   \n",
        "labels_010 = np.argmax(subject_010_predict, axis=-1)   \n",
        "labels_011 = np.argmax(subject_011_predict, axis=-1)   \n",
        "labels_012 = np.argmax(subject_012_predict, axis=-1)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChwS5wTUphwy"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Save subject_009_prediction\n",
        "labels_009_ext = []\n",
        "for i in range(labels_009.shape[0]):\n",
        "  for j in range(40):\n",
        "    labels_009_ext.append(labels_009[i])\n",
        "\n",
        "labels_009_ext_final = []\n",
        "for i in range(len(labels_009_ext)):\n",
        "  if i%2 ==0:\n",
        "    labels_009_ext_final.append(labels_009_ext[i])\n",
        "diff = test_009_length - len(labels_009_ext_final)\n",
        "for i in range(diff-1):\n",
        "  labels_009_ext_final.append(0)\n",
        "pd.DataFrame(labels_009_ext_final).to_csv('subject_009_01__y_prediction.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilB2IWuspirt"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Save subject_010_prediction\n",
        "\n",
        "labels_010_ext = []\n",
        "for i in range(labels_010.shape[0]):\n",
        "  for j in range(40):\n",
        "    labels_010_ext.append(labels_010[i])\n",
        "print(labels_010_ext)\n",
        "print(len(labels_010_ext))\n",
        "print(Counter(labels_010_ext))\n",
        "labels_010_ext_final = []\n",
        "for i in range(len(labels_010_ext)):\n",
        "  if i%2 ==0:\n",
        "    labels_010_ext_final.append(labels_010_ext[i])\n",
        "diff = test_010_length - len(labels_010_ext_final)\n",
        "for i in range(diff-1):\n",
        "  labels_010_ext_final.append(0)\n",
        "\n",
        "pd.DataFrame(labels_010_ext_final).to_csv('subject_010_01__y_prediction.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3dp9oTnpjov"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Save subject_011_prediction\n",
        "\n",
        "labels_011_ext = []\n",
        "for i in range(labels_011.shape[0]):\n",
        "  for j in range(40):\n",
        "    labels_011_ext.append(labels_011[i])\n",
        "print(labels_011_ext)\n",
        "print(len(labels_011_ext))\n",
        "print(Counter(labels_011_ext))\n",
        "labels_011_ext_final = []\n",
        "for i in range(len(labels_011_ext)):\n",
        "  if i%2 ==0:\n",
        "    labels_011_ext_final.append(labels_011_ext[i])\n",
        "diff = test_011_length - len(labels_011_ext_final)\n",
        "for i in range(diff-1):\n",
        "  labels_011_ext_final.append(0)\n",
        "pd.DataFrame(labels_011_ext_final).to_csv('subject_011_01__y_prediction.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6_bv6U7pkl0"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Save subject_012_prediction\n",
        "\n",
        "labels_012_ext = []\n",
        "for i in range(labels_012.shape[0]):\n",
        "  for j in range(40):\n",
        "    labels_012_ext.append(labels_012[i])\n",
        "print(labels_012_ext)\n",
        "print(len(labels_012_ext))\n",
        "print(Counter(labels_012_ext))\n",
        "labels_012_ext_final = []\n",
        "for i in range(len(labels_012_ext)):\n",
        "  if i%2 ==0:\n",
        "    labels_012_ext_final.append(labels_012_ext[i])\n",
        "diff = test_012_length - len(labels_012_ext_final)\n",
        "for i in range(diff-1):\n",
        "  labels_012_ext_final.append(0)\n",
        "\n",
        "pd.DataFrame(labels_012_ext_final).to_csv('subject_012_01__y_prediction.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dRCuTLGHk-Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}